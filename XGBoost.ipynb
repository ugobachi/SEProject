{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoostの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要そうなライブラリをインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn.metrics as metrics\n",
    "import librosa\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import optuna\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelname(Tr):\n",
    "    \"\"\"[summary]\n",
    "    training下のラベル名を取得\n",
    "    Returns:\n",
    "        [type]: [description]\n",
    "    \"\"\"    \n",
    "    current = os.getcwd()\n",
    "    if Tr == True:\n",
    "        filepath = current + '/train/'\n",
    "    elif Tr == False:\n",
    "        filepath = current + '/test/'\n",
    "    print(filepath)\n",
    "    labellist = []\n",
    "    for dir in os.listdir(filepath):\n",
    "        if os.path.isdir(os.path.join(filepath, dir))==True:\n",
    "            labellist.append(dir)\n",
    "    \n",
    "    return labellist, filepath\n",
    "\n",
    "def wav2list(p):\n",
    "    \"\"\"[summary]\n",
    "    Get audio file list to process all at once\n",
    "    Returns:\n",
    "        list : list of audio path\n",
    "    \"\"\"\n",
    "    p = Path(p)\n",
    "    audio_list = list(p.glob('*.wav'))\n",
    "\n",
    "    if len(audio_list) == 0:\n",
    "        sys.exit('Not found in {}'.format(p))\n",
    "\n",
    "    return audio_list\n",
    "\n",
    "def get_mfcc_librosa(p):\n",
    "    \"\"\"[summary]\n",
    "    librosaライブラリを用いて24次元MFCCを抽出する\n",
    "    データはtraining以下に置き, 各ラベルごとにフォルダを作ってデータを置いておく\n",
    "    Args:\n",
    "        p ([str]): .wavデータが置いてあるディレクトリ名\n",
    "    Returns:\n",
    "        [tupple]: (ファイル名, 24次元のMFCC)\n",
    "    \"\"\"    \n",
    "    wavlist = wav2list(p)\n",
    "    _name = []\n",
    "    _mfcc = []\n",
    "    wavlist.sort()\n",
    "\n",
    "    for wavfile in wavlist:\n",
    "        y, sr = librosa.core.load(wavfile,sr=44100)\n",
    "        tmp = librosa.feature.mfcc(y=y, sr=44100, hop_length=10, win_length=100, n_mfcc=24)\n",
    "        ceps = tmp.mean(axis=1)\n",
    "        # print(ceps)\n",
    "        _name.append(wavfile.stem)\n",
    "        _mfcc.append(ceps)\n",
    "\n",
    "    return _name, _mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データのデータフレーム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(Tr):\n",
    "    \"\"\"[summary]\n",
    "    trainディレクトリ下から.wavデータを取ってきて抽出したMFCCとラベルから構成されるデータフレームを作成\n",
    "    Returns:\n",
    "        df_new[dataframe]: 学習データのデータフレーム\n",
    "    \"\"\"    \n",
    "    labellist, filepath = get_labelname(Tr)\n",
    "    print(labellist)\n",
    "    cols = [x for x in range(24)]\n",
    "    print(cols)\n",
    "    cols.append('label')\n",
    "    print(cols)\n",
    "    df_new = pd.DataFrame(index = [], columns=cols)\n",
    "    # print(df_new)\n",
    "    for label in labellist:\n",
    "        # print(filepath, label)\n",
    "        labelpath = filepath + label\n",
    "        filename, tmp = get_mfcc_librosa(labelpath)\n",
    "        df = pd.DataFrame(tmp, index=filename)\n",
    "        df = df.assign(label=label)\n",
    "        df_new = pd.concat([df_new, df], axis=0)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataのデータフレーム作成 \n",
    "df = make_df(Tr=True)\n",
    "# x : 24次元のMFCC特徴量, y : データのラベル\n",
    "x = df.iloc[:, 0:24]\n",
    "y = df.iloc[:, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = set(y)\n",
    "label_list = list(label)\n",
    "label_list.sort()\n",
    "\n",
    "for i in range(len(label_list)):\n",
    "    y[y == label_list[i]] =i\n",
    "\n",
    "y = np.array(y, dtype = \"int\")\n",
    "print(len(y))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テストデータのデータフレーム作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = make_df(Tr=False)\n",
    "# x : 24次元のMFCC特徴量, y : データのラベル\n",
    "x_t = df_test.iloc[:, 0:24]\n",
    "y_t = df_test.iloc[:, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = set(y_t)\n",
    "label_list_test = list(label_test)\n",
    "label_list_test.sort()\n",
    "\n",
    "for i in range(len(label_list_test)):\n",
    "    y_t[y_t == label_list_test[i]] =i\n",
    "\n",
    "y_t = np.array(y_t, dtype = \"int\")\n",
    "print(len(y_t))\n",
    "y_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoostが扱うデータ形式にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = xgb.DMatrix(x, label=y)\n",
    "xgb_test = xgb.DMatrix(x_t, label=y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "XGBoostのパラメータを決める\n",
    " - objective : 多クラス分類でクラス別の確率をもとにクラスタリングを行うのでsoftmax\n",
    " - num_class : 4クラス分類 \n",
    "'''\n",
    "\n",
    "param = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価(パラメータチューニングなし)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_time = xgb.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_time.fit(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_t, y_predict)\n",
    "f1_test = f1_score(y_t, y_predict, average='weighted')\n",
    "\n",
    "print('accuracy : {}'.format(acc))\n",
    "print('accuracy : {}'.format(f1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価(グリッドサーチ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "params = {'eta': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "          'gamma': [0.001, 0.01, 0.1, 1],\n",
    "          'n_estimators': [100], 'max_depth':[2],\n",
    "          'min_child_weigh': [1], 'nthread': [2] }\n",
    "\n",
    "model = xgb.XGBClassifier(objective='multi:softmax') \n",
    "\n",
    "skf = StratifiedKFold(n_splits=20, shuffle=True, random_state=1)  \n",
    "clf = GridSearchCV(estimator=model, param_grid=params,   \n",
    "                    cv=skf, scoring=\"accuracy\", n_jobs=1, verbose=3)  \n",
    "clf.fit(x, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best score: %.4f\" % (clf.best_score_))  \n",
    "print(clf.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3,\n",
    "    'eta': 0.5, \n",
    "    'gamma': 0.01,\n",
    "    'max_depth': 2,\n",
    "    'nthread': 2,\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = xgb.train(param,\n",
    "                  xgb_train,\n",
    "                  num_boost_round=100,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(xgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と評価(Optunaによるハイパーパラメータ最適化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced = {0:3.5, 1:3.5, 2:1, 3:3}\n",
    "# balanced = {0:1, 1:1, 2:1, 3:1}\n",
    "xgboost_tuna = XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Functionの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1)\n",
    "def opt(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 0, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 5)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 50)\n",
    "    eta = trial.suggest_loguniform('eta', 0.01, 3.0)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.01, 0.3, 0.01)\n",
    "    xgboost_tuna = XGBClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators = n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        min_child_weight = min_child_weight,\n",
    "        eta = eta,\n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "    )\n",
    "    # 5分割してCrosss Validation\n",
    "    # kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    xgboost_tuna.fit(x, y, sample_weight=compute_sample_weight(\"balanced\", y))\n",
    "    tuna_pred_test = xgboost_tuna.predict(x_t)\n",
    "    \n",
    "    # scores = cross_validate(xgboost_tuna, X=X, y=y, cv=kf, scoring=['f1_weighted'])\n",
    "    \n",
    "    f1 = f1_score(y_t, tuna_pred_test, average=None)\n",
    "    return (1.0 - f1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(opt, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     colsample_bytree=study.best_params[\"colsample_bytree\"],\n",
    "fin_xgboost = XGBClassifier(\n",
    "    random_state=42,\n",
    "    n_estimators=study.best_params[\"n_estimators\"],\n",
    "    max_depth=study.best_params[\"max_depth\"],\n",
    "    min_child_weight=study.best_params[\"min_child_weight\"],\n",
    "    eta = study.best_params[\"eta\"],\n",
    "    subsample=study.best_params[\"subsample\"],\n",
    "    colsample_bytree=study.best_params[\"colsample_bytree\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_xgboost.fit(x, y, sample_weight=compute_sample_weight(\"balanced\", y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# テストデータで推測値を算出\n",
    "y_predict = fin_xgboost.predict(x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "fin_xgboost.predict(x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習ecopa, テストarena(混合行列はvoices, buzzer, whistle, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_t, y_predict)\n",
    "f1_test = f1_score(y_t, y_predict, average=None)\n",
    "precision_rbf_test = precision_score(y_t, y_predict, average=None)\n",
    "recall_rbf_test = recall_score(y_t, y_predict, average=None)\n",
    "\n",
    "print('accuracy : {}'.format(acc))\n",
    "print(\"Precision : \"+ str(precision_rbf_test))\n",
    "print(\"Recall : \"+ str(recall_rbf_test))\n",
    "print('f1: {}'.format(f1_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_t, y_predict)\n",
    "f1_test = f1_score(y_t, y_predict, average=None)\n",
    "precision_rbf_test = precision_score(y_t, y_predict, average=None)\n",
    "recall_rbf_test = recall_score(y_t, y_predict, average=None)\n",
    "\n",
    "print('accuracy : {}'.format(acc))\n",
    "print(\"Precision : \"+ str(precision_rbf_test))\n",
    "print(\"Recall : \"+ str(recall_rbf_test))\n",
    "print('f1: {}'.format(f1_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習arena, テストecopa(混合行列はvoices, buzzer, whistle, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_t, y_predict)\n",
    "f1_test = f1_score(y_t, y_predict, average=None)\n",
    "precision_rbf_test = precision_score(y_t, y_predict, average=None)\n",
    "recall_rbf_test = recall_score(y_t, y_predict, average=None)\n",
    "\n",
    "print('accuracy : {}'.format(acc))\n",
    "print(\"Precision : \"+ str(precision_rbf_test))\n",
    "print(\"Recall : \"+ str(recall_rbf_test))\n",
    "print('f1: {}'.format(f1_test))\n",
    "print('f1_mean: {}'.format(f1_test.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
